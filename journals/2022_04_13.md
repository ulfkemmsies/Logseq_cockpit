title:: 13.04.2022

- #card [[Markov Chain]] is a:
	- **stochastic model** describing a sequence of possible events in which the probability of each event **depends only on the state attained in the previous event**. ![Markov](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Markovkate_01.svg/220px-Markovkate_01.svg.png)
- 10:30 Watched this video about [[Reinforcement Learning]] and [[Markov Process]]es: {{youtube https://www.youtube.com/watch?v=cRe70GVW2Os}}
	- Notes:
		- {{youtube-timestamp 75}} Markov Decision Process:
			- Discrete Control Problems: stochastic control process
			- Memoryless: States only depend on previous state, not on past beyond that
			- [[Markov Chain]] is a subcategory of Markov Process
		- {{youtube-timestamp 227}} Decision Process and Game Theory:
			- Players in games
			- Decision Theory applicable for single agents, GT for multiple
			- Decision process based on reward based on rationality (optmization of some outcome)
		- {{youtube-timestamp 389}}
			- Steps are discrete
			- Stochastic means state transitions are probabilistic
				- MDP are stochastic
		- {{youtube-timestamp 445}} Some things are in your control and some things are not
		- {{youtube-timestamp 677}}
			- Reward function is dependent on state transition $$R_a (S_{t}, S_{t+1})$$, where $$a$$ is the action taken
			- Similarly, the probability of state transition (which is a property of Markov Chain) is $$P_a (S_{t}, S_{t+1})$$ also depends on our action $$a$$
			- Discounting is used (similarly to finance) with $$\Gamma$$ where what we are trying to maximize is $$\Sigma_{t=0}^{\infty} \Gamma^{t} R_0(S_{t-1}, S_{t})$$
		-
			-
- 11:07 Watched another video by same channel {{youtube https://www.youtube.com/watch?v=fiSfQDuu68E}}
	-
- ![Why retraining is important](https://i0.wp.com/neptune.ai/wp-content/uploads/Retraining-models-graph.jpg?resize=768%2C645&ssl=1)
- 15:02 Found [River](https://github.com/online-ml/river) for online machine learning, which is when data is streamed one observation at a time as opposed to batch learning. This is perfect for dynamic timeseries forecasting.
-